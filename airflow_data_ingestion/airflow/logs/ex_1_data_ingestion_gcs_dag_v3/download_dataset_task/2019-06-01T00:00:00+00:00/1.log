[2022-02-02 18:18:32,905] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ex_1_data_ingestion_gcs_dag_v3.download_dataset_task scheduled__2019-06-01T00:00:00+00:00 [queued]>
[2022-02-02 18:18:32,924] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ex_1_data_ingestion_gcs_dag_v3.download_dataset_task scheduled__2019-06-01T00:00:00+00:00 [queued]>
[2022-02-02 18:18:32,925] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-02 18:18:32,926] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-02-02 18:18:32,927] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-02 18:18:32,939] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-06-01 00:00:00+00:00
[2022-02-02 18:18:32,947] {standard_task_runner.py:52} INFO - Started process 8898 to run task
[2022-02-02 18:18:32,951] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ex_1_data_ingestion_gcs_dag_v3', 'download_dataset_task', 'scheduled__2019-06-01T00:00:00+00:00', '--job-id', '319', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_hw_1_ex.py', '--cfg-path', '/tmp/tmpezel142o', '--error-file', '/tmp/tmp533iovm6']
[2022-02-02 18:18:32,953] {standard_task_runner.py:77} INFO - Job 319: Subtask download_dataset_task
[2022-02-02 18:18:33,025] {logging_mixin.py:109} INFO - Running <TaskInstance: ex_1_data_ingestion_gcs_dag_v3.download_dataset_task scheduled__2019-06-01T00:00:00+00:00 [running]> on host 700aeb16bae0
[2022-02-02 18:18:33,069] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-02-02 18:18:33,092] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ex_1_data_ingestion_gcs_dag_v3
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-06-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-06-01T00:00:00+00:00
[2022-02-02 18:18:33,094] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-02 18:18:33,096] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sS https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-06.csv > /opt/***/yellow_tripdata_2019-06.csv']
[2022-02-02 18:18:33,112] {subprocess.py:85} INFO - Output:
[2022-02-02 18:21:39,486] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-02 18:21:39,609] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ex_1_data_ingestion_gcs_dag_v3, task_id=download_dataset_task, execution_date=20190601T000000, start_date=20220202T181832, end_date=20220202T182139
[2022-02-02 18:21:39,728] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-02 18:21:39,853] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-02-10 12:55:55,153] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ex_1_data_ingestion_gcs_dag_v3.download_dataset_task scheduled__2019-06-01T00:00:00+00:00 [queued]>
[2022-02-10 12:55:55,167] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ex_1_data_ingestion_gcs_dag_v3.download_dataset_task scheduled__2019-06-01T00:00:00+00:00 [queued]>
[2022-02-10 12:55:55,168] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-10 12:55:55,169] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-02-10 12:55:55,170] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-10 12:55:55,182] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-06-01 00:00:00+00:00
[2022-02-10 12:55:55,188] {standard_task_runner.py:52} INFO - Started process 1109 to run task
[2022-02-10 12:55:55,193] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ex_1_data_ingestion_gcs_dag_v3', 'download_dataset_task', 'scheduled__2019-06-01T00:00:00+00:00', '--job-id', '675', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_hw_1_ex.py', '--cfg-path', '/tmp/tmpcdt0jtm_', '--error-file', '/tmp/tmpfkrga4j9']
[2022-02-10 12:55:55,195] {standard_task_runner.py:77} INFO - Job 675: Subtask download_dataset_task
[2022-02-10 12:55:55,265] {logging_mixin.py:109} INFO - Running <TaskInstance: ex_1_data_ingestion_gcs_dag_v3.download_dataset_task scheduled__2019-06-01T00:00:00+00:00 [running]> on host e30f201fae61
[2022-02-10 12:55:55,311] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-02-10 12:55:55,340] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ex_1_data_ingestion_gcs_dag_v3
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-06-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-06-01T00:00:00+00:00
[2022-02-10 12:55:55,342] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-10 12:55:55,343] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sS https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-06.csv > /opt/***/yellow_tripdata_2019-06.csv']
[2022-02-10 12:55:55,358] {subprocess.py:85} INFO - Output:
[2022-02-10 12:57:27,471] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-10 12:57:27,518] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ex_1_data_ingestion_gcs_dag_v3, task_id=download_dataset_task, execution_date=20190601T000000, start_date=20220210T125555, end_date=20220210T125727
[2022-02-10 12:57:27,588] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-10 12:57:27,635] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-02-10 15:34:11,216] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ex_1_data_ingestion_gcs_dag_v3.download_dataset_task scheduled__2019-06-01T00:00:00+00:00 [queued]>
[2022-02-10 15:34:11,241] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ex_1_data_ingestion_gcs_dag_v3.download_dataset_task scheduled__2019-06-01T00:00:00+00:00 [queued]>
[2022-02-10 15:34:11,243] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-10 15:34:11,246] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-02-10 15:34:11,247] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-10 15:34:11,262] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-06-01 00:00:00+00:00
[2022-02-10 15:34:11,272] {standard_task_runner.py:52} INFO - Started process 373 to run task
[2022-02-10 15:34:11,278] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ex_1_data_ingestion_gcs_dag_v3', 'download_dataset_task', 'scheduled__2019-06-01T00:00:00+00:00', '--job-id', '795', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_hw_1_ex.py', '--cfg-path', '/tmp/tmplhgxmcm2', '--error-file', '/tmp/tmpjm_34r1y']
[2022-02-10 15:34:11,280] {standard_task_runner.py:77} INFO - Job 795: Subtask download_dataset_task
[2022-02-10 15:34:11,373] {logging_mixin.py:109} INFO - Running <TaskInstance: ex_1_data_ingestion_gcs_dag_v3.download_dataset_task scheduled__2019-06-01T00:00:00+00:00 [running]> on host 276a0ad90304
[2022-02-10 15:34:11,480] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-02-10 15:34:11,528] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ex_1_data_ingestion_gcs_dag_v3
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-06-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-06-01T00:00:00+00:00
[2022-02-10 15:34:11,531] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-10 15:34:11,533] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sS https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-06.csv > /opt/***/yellow_tripdata_2019-06.csv']
[2022-02-10 15:34:11,552] {subprocess.py:85} INFO - Output:
[2022-02-10 15:35:17,152] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-10 15:35:17,204] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ex_1_data_ingestion_gcs_dag_v3, task_id=download_dataset_task, execution_date=20190601T000000, start_date=20220210T153411, end_date=20220210T153517
[2022-02-10 15:35:17,262] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-10 15:35:17,322] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-02-10 16:33:51,395] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ex_1_data_ingestion_gcs_dag_v3.download_dataset_task scheduled__2019-06-01T00:00:00+00:00 [queued]>
[2022-02-10 16:33:51,428] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: ex_1_data_ingestion_gcs_dag_v3.download_dataset_task scheduled__2019-06-01T00:00:00+00:00 [queued]>
[2022-02-10 16:33:51,430] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-10 16:33:51,432] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-02-10 16:33:51,433] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-10 16:33:51,462] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-06-01 00:00:00+00:00
[2022-02-10 16:33:51,475] {standard_task_runner.py:52} INFO - Started process 351 to run task
[2022-02-10 16:33:51,491] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'ex_1_data_ingestion_gcs_dag_v3', 'download_dataset_task', 'scheduled__2019-06-01T00:00:00+00:00', '--job-id', '937', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_hw_1_ex.py', '--cfg-path', '/tmp/tmphzm2f06i', '--error-file', '/tmp/tmp54m12e6c']
[2022-02-10 16:33:51,494] {standard_task_runner.py:77} INFO - Job 937: Subtask download_dataset_task
[2022-02-10 16:33:51,611] {logging_mixin.py:109} INFO - Running <TaskInstance: ex_1_data_ingestion_gcs_dag_v3.download_dataset_task scheduled__2019-06-01T00:00:00+00:00 [running]> on host 106a34111faf
[2022-02-10 16:33:51,721] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-02-10 16:33:51,796] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ex_1_data_ingestion_gcs_dag_v3
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-06-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-06-01T00:00:00+00:00
[2022-02-10 16:33:51,800] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-10 16:33:51,803] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sS https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-06.csv > /opt/***/yellow_tripdata_2019-06.csv']
[2022-02-10 16:33:51,836] {subprocess.py:85} INFO - Output:
[2022-02-10 16:34:18,830] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-10 16:34:18,886] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=ex_1_data_ingestion_gcs_dag_v3, task_id=download_dataset_task, execution_date=20190601T000000, start_date=20220210T163351, end_date=20220210T163418
[2022-02-10 16:34:18,936] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-10 16:34:18,993] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
